Outline

1. I've been reading jurassic park again (did you know it was a book?), and some passages from Ian Malcolm  about jurrasic park are almost directly applicable to AI.
2. Everyone has already seen the meme "we were so busy wondering if we could do it, we didn't stop to think if we should do it". That's a great clip from the movie, but the book dives into a much deeper explaination of what science is and the value of **experience**, that AI will never have.
3. My predictions? Eventually people will be trusting AI too much. We've already seen it with AI hallucinating court cases that become cited, the AI generated image of princess kate, etc. This is just the start. In the book, the groundskeepers didn't know how the power of the animals, so extra safety measures needed to be installed (like bars on the windows). Poeple may be realizing what AI is good at, but what happens when the AI starts "breeding?" like the raptors did in the book? In the book, the scientists didn't realize the animals were breeding because they only tested the happy path (i.e check that 243 animals are in the park). If there are more animals, then the test passes. This was a naive test of course, and I'm sure people at openAI have more rigorous testing. But do we even know what a Jurassic park senario looks like with AI? At one point, there could be a big blunder with AI, imagine our national security because AI has made a mistake. This could be equivalent to dennis nedry sabatoging the park and turning off the power. When it seems order is restored, all things can get much worse, much faster. In the book, power seems to be restored, but it turns out that only auxiliary power was restored. The electrical fences don't run on auxilary power, so the raptors got out. In an AI world, some national security check done by AI is replaced with humans, and order is quickly resotred. But what if those humans cannot perform the tasks of AI as quickly? Maybe they start to miss a very clear targeted attack that an AI would detect under normal circumstances? I think eventually, the raptors will get into our visitor center, and there will be mayhem. People will become very wary of using AI for any critical tasks, but not other stuff, idk. And then, someone will throw a bunch of money at AI again in 20 years, and say they fixed all the problems. Some andromimous rex AI will be created and we will repeat thte cycle again.


Also draw the parallel to the fact that, Richard hammond chose to develop the park on isla nublar because there were no regulations! Are there any regulations on AI currently? 

https://www.w3.org/reports/ai-web-impact/ <- maybe read this and reference it potentially?

https://arstechnica.com/gadgets/2024/04/fake-ai-law-firms-are-sending-fake-dmca-threats-to-generate-fake-seo-gains/
